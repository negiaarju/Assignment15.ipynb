{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?\n",
        "\n",
        "**Simple Linear Regression** is a statistical and machine learning method used to model the relationship between **one independent variable (X)** and **one dependent variable (Y)** by fitting a straight line to the data.\n",
        "\n",
        "It assumes that the relationship between X and Y is **linear**.\n",
        "\n",
        "### Mathematical Equation\n",
        "\n",
        "[\n",
        "Y = mX + c\n",
        "]\n",
        "Where:\n",
        "\n",
        "* **Y** = dependent variable (output)\n",
        "* **X** = independent variable (input)\n",
        "* **m** = slope (change in Y for a one-unit change in X)\n",
        "* **c** = intercept (value of Y when X = 0)\n",
        "\n",
        "### Purpose\n",
        "\n",
        "* To **predict** the value of Y based on X\n",
        "* To **understand** how changes in X affect Y\n",
        "\n",
        "### Example\n",
        "\n",
        "Predicting **house price (Y)** based on **house size (X)**.\n",
        "\n",
        "### Key Points (Short)\n",
        "\n",
        "* Uses **one input variable**\n",
        "* Fits a **straight line**\n",
        "* Based on minimizing **error (least squares method)**\n",
        "* Widely used for **prediction and trend analysis**\n"
      ],
      "metadata": {
        "id": "bOKmn7GrLU-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "The **key assumptions of Simple Linear Regression** are:\n",
        "\n",
        "1. **Linearity**\n",
        "   The relationship between the independent variable (X) and dependent variable (Y) is linear.\n",
        "\n",
        "2. **Independence**\n",
        "   Observations are independent of each other (no correlation between errors).\n",
        "\n",
        "3. **Homoscedasticity**\n",
        "   The variance of errors is constant across all values of X.\n",
        "\n",
        "4. **Normality of Errors**\n",
        "   The residuals (errors) are normally distributed.\n",
        "\n",
        "5. **No or Minimal Outliers**\n",
        "   There are no extreme outliers that strongly influence the regression line.\n",
        "\n"
      ],
      "metadata": {
        "id": "K0AZUmAeLg-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is heteroscedasticity, and why is it important to address in regression models?\n",
        "\n",
        "**Heteroscedasticity** occurs in a regression model when the **variance of the error terms (residuals) is not constant** across all levels of the independent variable(s).\n",
        "\n",
        "### In Simple Terms\n",
        "\n",
        "As X changes, the spread of errors increases or decreases instead of remaining uniform.\n",
        "\n",
        "### Why It Is Important to Address\n",
        "\n",
        "* **Biased standard errors** → incorrect confidence intervals\n",
        "* **Unreliable hypothesis tests** → t-tests and p-values become misleading\n",
        "* **Inefficient estimates** → coefficients are still unbiased but not optimal\n",
        "* **Poor model interpretation** → predictions at some X values become less reliable\n",
        "\n",
        "### Common Causes\n",
        "\n",
        "* Presence of outliers\n",
        "* Skewed data\n",
        "* Incorrect model specification\n",
        "* Large differences in scale of variables\n",
        "\n",
        "### How to Detect\n",
        "\n",
        "* Residual vs fitted value plots\n",
        "* Breusch–Pagan test\n",
        "* White test\n",
        "\n",
        "### How to Fix\n",
        "\n",
        "* Apply transformations (log, square root)\n",
        "* Use **Weighted Least Squares (WLS)**\n",
        "* Use **robust standard errors**\n",
        "* Add missing variables\n"
      ],
      "metadata": {
        "id": "rTt5il6dLtpt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is Multiple Linear Regression?\n",
        "\n",
        "**Multiple Linear Regression (MLR)** is a statistical technique used to model the relationship between **one dependent variable (Y)** and **two or more independent variables (X₁, X₂, …, Xₙ)**.\n",
        "\n",
        "It extends Simple Linear Regression by using multiple predictors to explain or predict the outcome.\n",
        "\n",
        "### Mathematical Equation\n",
        "\n",
        "[\n",
        "Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\cdots + \\beta_nX_n + \\varepsilon\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* **Y** = dependent variable\n",
        "* **X₁, X₂, …, Xₙ** = independent variables\n",
        "* **β₀** = intercept\n",
        "* **β₁, β₂, …, βₙ** = coefficients (effect of each X on Y, holding others constant)\n",
        "* **ε** = error term\n",
        "\n",
        "### Purpose\n",
        "\n",
        "* To **predict** Y using multiple factors\n",
        "* To **understand the individual impact** of each independent variable\n",
        "\n",
        "### Example\n",
        "\n",
        "Predicting **house price** based on **size, location, number of rooms, and age of the house**.\n",
        "\n",
        "### Key Points (Short)\n",
        "\n",
        "* Uses **multiple input variables**\n",
        "* Assumes a **linear relationship**\n",
        "* Helps control for **confounding variables**\n",
        "* Widely used in **data analysis and machine learning**\n"
      ],
      "metadata": {
        "id": "0roSwh-5L_l1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is polynomial regression, and how does it differ from linear\n",
        "regression?\n",
        "\n",
        "**Polynomial Regression** is a type of regression that models the relationship between the independent variable(s) and the dependent variable as an **nth-degree polynomial**. It is used when the relationship between variables is **non-linear**.\n",
        "\n",
        "### Polynomial Regression Equation\n",
        "\n",
        "[\n",
        "Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\cdots + \\beta_nX^n + \\varepsilon\n",
        "]\n",
        "\n",
        "---\n",
        "\n",
        "### How It Differs from Linear Regression\n",
        "\n",
        "| Aspect       | Linear Regression        | Polynomial Regression                         |\n",
        "| ------------ | ------------------------ | --------------------------------------------- |\n",
        "| Relationship | Straight-line (linear)   | Curved (non-linear)                           |\n",
        "| Model form   | (Y = mX + c)             | (Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\dots) |\n",
        "| Complexity   | Simple                   | More flexible                                 |\n",
        "| Fit          | May underfit curved data | Fits non-linear patterns better               |\n",
        "| Risk         | Low overfitting          | Higher overfitting with high degree           |\n",
        "\n",
        "---\n",
        "\n",
        "### Key Points\n",
        "\n",
        "* Polynomial regression is **linear in parameters**, but **non-linear in variables**\n",
        "* Degree of polynomial controls model flexibility\n",
        "* Choosing a very high degree can lead to **overfitting**\n",
        "\n",
        "### Example\n",
        "\n",
        "Predicting **sales growth** over time where growth accelerates or decelerates.\n"
      ],
      "metadata": {
        "id": "XU64sQ4WMLAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Implement a Python program to fit a Simple Linear Regression model to\n",
        "the following sample data:\n",
        "\n",
        "Here’s a complete **Python implementation of Simple Linear Regression** with a plot of the regression line over the data points.\n",
        "\n",
        "### Explanation (Short)\n",
        "\n",
        "* We use **NumPy** for data handling\n",
        "* **scikit-learn’s LinearRegression** to fit the model\n",
        "* **Matplotlib** to visualize data points and the regression line\n",
        "\n",
        "### Model Results\n",
        "\n",
        "* **Slope (m)** ≈ **1.98**\n",
        "* **Intercept (c)** ≈ **0.18**\n",
        "\n",
        "So, the fitted equation is approximately:\n",
        "[\n",
        "Y = 1.98X + 0.18\n",
        "]\n",
        "\n",
        "### What the Plot Shows\n",
        "\n",
        "* Scatter points → actual data\n",
        "* Straight line → predicted values from the regression model\n",
        "\n"
      ],
      "metadata": {
        "id": "Y7IgHZ66MWi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Fit a Multiple Linear Regression model on this sample data:\n",
        "\n",
        "Here is the **Multiple Linear Regression model** fitted to the given data.\n",
        "\n",
        "### Model Used\n",
        "\n",
        "[\n",
        "\\text{Price} = \\beta_0 + \\beta_1(\\text{Area}) + \\beta_2(\\text{Rooms})\n",
        "]\n",
        "\n",
        "### Fitted Model Parameters\n",
        "\n",
        "* **Intercept (β₀)** ≈ **103,157.89**\n",
        "* **Coefficient for Area (β₁)** ≈ **63.16**\n",
        "* **Coefficient for Rooms (β₂)** ≈ **34,736.84**\n",
        "\n",
        "### Final Regression Equation\n",
        "\n",
        "[\n",
        "\\text{Price} = 103157.89 + 63.16 \\times \\text{Area} + 34736.84 \\times \\text{Rooms}\n",
        "]\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "* For every **1 sq ft increase in area**, price increases by approximately **₹63.16**, keeping rooms constant.\n",
        "* Adding **one extra room** increases the price by approximately **₹34,736.84**, keeping area constant.\n"
      ],
      "metadata": {
        "id": "jGWC4ZWwMv6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Implement polynomial regression on the following data:\n",
        "\n",
        "Here is the **implementation of Polynomial Regression** (degree = 2) for the given data.\n",
        "\n",
        "### Model Used\n",
        "\n",
        "[\n",
        "Y = \\beta_0 + \\beta_1X + \\beta_2X^2\n",
        "]\n",
        "\n",
        "### Fitted Model Parameters\n",
        "\n",
        "* **Intercept (β₀)** ≈ **0.06**\n",
        "* **β₁ (X)** ≈ **1.94**\n",
        "* **β₂ (X²)** ≈ **0.20**\n",
        "\n",
        "### Final Polynomial Equation\n",
        "\n",
        "[\n",
        "Y \\approx 0.06 + 1.94X + 0.20X^2\n",
        "]\n",
        "\n",
        "### Explanation\n",
        "\n",
        "* Polynomial regression captures the **curved (non-linear) trend** in the data.\n",
        "* The scatter points show the actual data.\n",
        "* The smooth curve represents the polynomial regression fit.\n"
      ],
      "metadata": {
        "id": "ZCQ7rUI8NDQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Create a residuals plot for a regression model trained on this data:\n",
        "\n",
        "Step 1: Calculate the Residuals\n",
        "The first step is to fit a linear regression model to the data to find the predicted values ($\\hat{Y}$) and then calculate the residuals ($e$) using the formula: $e = Y - \\hat{Y}$. The linear model has the equation $y = 1.15x + 6.5$ (calculated by the Python code). The residuals are calculated as:\n",
        "\n",
        "• For $X=10$: $e = 15 - (1.15 \\times 10 + 6.5) = 15 - 18 = -3$\n",
        "• For $X=20$: $e = 35 - (1.15 \\times 20 + 6.5) = 35 - 29.5 = 5.5$\n",
        "• For $X=30$: $e = 40 - (1.15 \\times 30 + 6.5) = 40 - 41 = -1$\n",
        "• For $X=40$: $e = 50 - (1.15 \\times 40 + 6.5) = 50 - 52.5 = -2.5$\n",
        "• For $X=50$: $e = 65 - (1.15 \\times 50 + 6.5) = 65 - 64 = 1$\n",
        "\n",
        "Step 2: Plot Residuals Against the Independent Variable [5]  \n",
        "A residuals plot is a scatter plot with the independent variable ($X$) on the horizontal axis and the corresponding residuals ($e$) on the vertical axis. The points should be plotted as $(X, e)$. [6]  \n",
        "Answer:\n",
        "The residual plot is a scatter plot of the following points:\n",
        "\n",
        "• (10, -3)\n",
        "• (20, 5.5)\n",
        "• (30, -1)\n",
        "• (40, -2.5)\n",
        "• (50, 1)\n",
        "\n",
        "The plot would show these points randomly dispersed around the horizontal axis (the $e=0$ line), with no discernible pattern, indicating that a linear model is appropriate for this data. [7, 8]  \n",
        "\n"
      ],
      "metadata": {
        "id": "4NZQ1Wn9NUJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Imagine you are a data scientist working for a real estate company. You\n",
        "need to predict house prices using features like area, number of rooms, and location.\n",
        "However, you detect heteroscedasticity and multicollinearity in your regression model. Explain the steps you would take to address these issues and ensure a robust model.\n",
        "\n",
        "As a data scientist, I would handle **heteroscedasticity** and **multicollinearity** systematically to ensure the regression model is **reliable, interpretable, and accurate**.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Addressing Heteroscedasticity\n",
        "\n",
        "(Heteroscedasticity = non-constant variance of errors)\n",
        "\n",
        "### Step 1: Detect the problem\n",
        "\n",
        "* Plot **residuals vs predicted values**\n",
        "* Use statistical tests:\n",
        "\n",
        "  * Breusch–Pagan test\n",
        "  * White test\n",
        "\n",
        "### Step 2: Apply solutions\n",
        "\n",
        "* **Transform the target variable**\n",
        "\n",
        "  * Log(price), square root, or Box-Cox transformation\n",
        "* **Use robust standard errors**\n",
        "\n",
        "  * Heteroscedasticity-consistent (HC) standard errors\n",
        "* **Weighted Least Squares (WLS)**\n",
        "\n",
        "  * Give less weight to observations with high variance\n",
        "* **Improve model specification**\n",
        "\n",
        "  * Add missing variables (e.g., neighborhood quality, amenities)\n",
        "\n",
        "### Outcome\n",
        "\n",
        "✔ Correct confidence intervals\n",
        "✔ Reliable hypothesis tests\n",
        "✔ Better prediction stability\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Addressing Multicollinearity\n",
        "\n",
        "(Multicollinearity = high correlation among predictors)\n",
        "\n",
        "### Step 1: Detect the problem\n",
        "\n",
        "* Correlation matrix / heatmap\n",
        "* Variance Inflation Factor (VIF)\n",
        "\n",
        "  * VIF > 5 or 10 indicates a problem\n",
        "\n",
        "### Step 2: Apply solutions\n",
        "\n",
        "* **Remove or combine correlated variables**\n",
        "\n",
        "  * Example: area and carpet area → keep one\n",
        "* **Feature engineering**\n",
        "\n",
        "  * Create ratios or aggregated features\n",
        "* **Dimensionality reduction**\n",
        "\n",
        "  * Principal Component Analysis (PCA)\n",
        "* **Regularization techniques**\n",
        "\n",
        "  * Ridge Regression (L2)\n",
        "  * Lasso Regression (L1)\n",
        "\n",
        "### Outcome\n",
        "\n",
        "✔ Stable coefficient estimates\n",
        "✔ Improved interpretability\n",
        "✔ Reduced variance in predictions\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Model Validation & Final Checks\n",
        "\n",
        "* Use **train–test split or cross-validation**\n",
        "* Compare models using **RMSE, MAE, R²**\n",
        "* Re-check residual plots after fixes\n",
        "* Ensure assumptions are reasonably satisfied\n",
        "\n"
      ],
      "metadata": {
        "id": "fI5QhlBrN1c-"
      }
    }
  ]
}